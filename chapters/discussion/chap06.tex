%
% File: chap06.tex
% Author: Antigoni Kourou
% Description: Discussion
%
\let\textcircled=\pgftextcircled
\chapter{Discussion}
\label{chap:dis}
%\initial{H}
\section{Major findings}
Getting insights about features hidden in free text is an important step towards better customer feedback analysis. The proposed approach on the first stage extract features from text based on the accommodation ontology, secondly it detects the sentiment of each sentence and assigns it to the features mentioned in each sentence respectively. Thus, the pipeline returns all the sentiment scores of sentences and features, which are then grouped and calculated for reviews and listings. This work is most similar to \cite{eirinaki2012feature,ali2015type,penalver2014feature} in the concepts discussed in the second chapter, however mining the text for quantitative analysis purposes is a novel approach. 

As part of the main findings, this paper shows the alignment between the quantitative data of Airbnb and the output of the pipeline. Furthermore it suggests that there is a systematic tendency of Airbnb ratings to be higher than the ratings generated from text feedback. This tendency consist of half a star, which is recommended to be reduced from the Airbnb system ratings. In addition, we show that the reviewers are in general very positive in their text messages as indicated by their star ratings. However we showed that the text reviews can reveal hidden knowledge which can not be obtained only by analyzing the ratings in the feedback system. Thus, even though the overall ratings of a listing align between pipeline and Airbnb, in feature level it is important that we mine the text as it influences features' ratings. We found out that the most mentioned features in the reviews are \textit{location, value} and \textit{cleanliness}. Their sentiment is necessary that to be conditioned based on the number of reviews, where the feature is mentioned within a listing. The minimum number of reviews referring to a certain feature within a listing is set to 3, the same limit that Airbnb uses for calculating their average star ratings. With this condition set, we found out that 16.5\% of the listings do not have enough reviews for generating reliable scores about sentiment of features.

The analysis of user generated content in Airbnb system includes both customer and business perspective, therefore it is seen as an interesting aspect to explore further than this research. The evaluation of the pipeline showed that it successfully detects the sentiment of the sentences, and for the second task, that of feature extraction, the pipeline reached an average precision of 77.7\% and recall 79.2\%. However, for explaining possible downfalls of the proposed approach, the following subsection will describe the limitation and future work to be done for improving the pipeline and it will be followed by the practical implications of this work. 

\section{Practical implications}
With the increase of user generated content, service providers and businesses deal with the challenge of reducing the costs of having employees to read through large amounts of text data such as
surveys, Web documents, blogs, reviews,and social media sites in order to extract needed information. Having this analysis automated and detailed into discrete opinion scores reduces significantly these costs. Secondly, it gives to businesses a priority advantage of keeping track of a measurable impact that their product or services have in the crowds. In addition, it provides them a clear panorama on which aspects they need to improve, which aspects their competitors are doing better and also the aspects on which their services are superior in the market. Furthermore, having the insights of text reviews in the form of quantitative data allows businesses to customize the analysis and the insights they want to take out of this data. In the same time, these tasks can be performed by an employee who has no knowledge about opinion mining and they wouldn't need to, because the output is just a traditional format of quantitative data, suitable for analyze with Excel, SPSS, Matlab and so further.

From the customer point of view, having the service owners better understood their needs, they will have better services. Furthermore, users will get encouraged to write more reviews as their voice with be heard, opposite of the case when a review ends up in the 5th page of a listing and it is read by less than 3\% of other users \cite{pavlou2006institutional}. In addition, if the ratings generated from text will complement the star rating system as suggested, the results would be more reliable and users' work on would be reduced. Finally, with the right implementation of the pipeline in search engines the customers will be able to directly rank the results based on their required features. 

\section{Limitations and future research}
This study has several limitation, which create room for further research. Due to the time-frame this research is based only in six accommodation features that are mentioned in the Airbnb website. In order for the study to be complete every feature of the accommodation ontology will have to be treated. This step would give meaning to all the sentences of reviews by clustering them into one or more features and would decrease the phenomenon of having too many sentences with un-identified objects. Secondly, this research groups all the accommodation features in the same family root without making a distinction between explicit and implicit features. The last ones are more difficult to process in NLP, however different academics have taken steps in this direction. A N-gram approach is very important to be tested and it is believed to improve the performance of the pipeline for feature identification. For example in phrases like \textit{"The room was \textbf{as in} the \textbf{pictures"}} is a potential 3-gram phrase which refers to \textit{accuracy}. Thirdly, for sentiment detection the paper discusses the use of VADER, however several algorithms (i.e. SO-CAL, SenticNet, Pattern)  can be trained in the corpus for performance comparison purposes. 


In addition, the evaluation of the pipeline requires higher values for TP/FP which affects the reliability of the precision and recall measurement. Thus, the evaluation will have to be improved either by increasing the number of features identified as discussed above or by increasing the number of sentences in the evaluation set, so we will have more cases to evaluate. Lastly, the pipeline ignores all the reviews in languages other than English. In the Amsterdam's dataset, around 17\% of the whole reviews ignored, meaning that from 30.2 reviews in average per listing, 5.1 reviews in average will be ignored. The ignored reviews are written mostly in Dutch, but also other languages. This percentage is expected to increase in cities other than Amsterdam. Therefore, the pipeline has to be trained for languages other than English, such as Dutch, French, Spanish and German, which correspond with the countries of biggest Airbnb impact in Europe. For doing so, the accommodation ontology has to be adjusted to these languages and secondly the sentiment detector must support those languages. However, the limitation on language and sentiment detection are part of the limitations of every tool which deals NLP, as new and non consolidated field of research \cite{ravi2015survey}.


% -----------------------------------------------------------
