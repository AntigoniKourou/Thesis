%
% File: chap06.tex
% Author: Antigoni Kourou
% Description: Discussion
%
\let\textcircled=\pgftextcircled
\chapter{Discussion}
\label{chap:dis}
%\initial{H}
\section{Discussion of main findings}
This paper investigates how feature-based sentiment mining can be aligned with analysis of quantitative data. The proposed approach, on the first stage, extracts features from text reviews of Airbnb based on the accommodation ontology, secondly it detects the sentiment of each sentence and it assigns this scores to the features mentioned on them. The output of these stages are all the sentiment scores of sentences and their features. Then in the third stage, these sentiment scores are then analyzed in three granularity levels: \textit{sentence, review} and \textit{listing}. This work is most similar to \cite{eirinaki2012feature, ali2015type, penalver2014feature} in the concept of the pipeline and the used methods for feature extraction and sentiment detection. The added value of this paper is the novel approach of bringing together the analysis of qualitative and quantitative data.

From the analysis of the sentiment score of Airbnb reviews, we found out that there is a systematic tendency of Airbnb ratings to be higher than the ratings generated from text feedback. This tendency is estimated to be half a star difference in overall ratings. Thus, shifting the Airbnb values with -0.5 stars, proved to produce more reliable rating scores. This conclusion is supported by evaluation of the pipeline generated sentiment scores, which when calculates in average predict precisely the human ratings.
Secondly, this paper confirms once again the observation of a J-shaped distribution of ratings in feedback systems. This means that the reviews are in general very positive and they tend to avoid the neutral zones. The presence of 17.2\% of the sentences with no-sentiment revealed the number of cancellations per listing, as well the inability of the pipeline to detect the sentiment of many sentences. Their exclusion from the analysis may represent a downfall of overall report. Thirdly, the results show that text reviews can reveal hidden knowledge which can not be obtained only by analyzing quantitative ratings. This hidden knowledge is linked directly with the analysis in feature level and it is noticed when analyzing the overall ratings. However, it is very important to condition the number of reviews for a feature of a listing, as 16.5\% of the listings do not have enough reviews for generating reliable scores for the sentiment of features in a single listing. In this paper, this limit is set to 3, but this number is relative and represents an issue for further discussion. Lastly, we found out that the most mentioned features in the reviews is \textit{location}, while the least mentioned ones are \textit{check-in and accuracy}.  This conclusion is however arguable, because it fully relies on how good can the pipeline identify each feature. For example, the evaluation results reveals that 50\% of the sentences, where the customer talks about \textit{check-in} or \textit{accuracy} are missed from the pipeline. However, these two features represent the least mentioned ones even in the corpus of 100 sentences for evaluation. In average, the pipeline reached the precision of 77.7\% and recall 79.2\% for feature extraction, highly comparable with the three other systems who use ontology-based feature extraction \cite{eirinaki2012feature, penalver2014feature, ali2015type}. For guiding the future research in overcoming the downfalls of this proposed approach, the following subsection describes the limitation of this paper and gives several suggestions for future work to be done.

\section{Limitations and future research}
This study has several limitation, which create room for further research. Due to restrictions in time-frame, this research is based only in six accommodation features from the whole ontology, which are mentioned in the Airbnb website. In order for the study to be complete, every feature of the accommodation ontology must be extracted by the pipeline. This step would give meaning to all the sentences of reviews, by clustering them into one or more features. Furthermore, by extending the list of extracted features, we would decrease the phenomenon of having a high number of sentences, that do not refer to any object. Secondly, this research groups all the accommodation features in the same family root without making a distinction between explicit and implicit features. The last ones are more difficult to process in NLP, however not impossible to be identified. Their extraction required the integration of a hybrid approach which includes machine learning, besides the ontologies. In addition to these thoughts, it is very important to apply a N-gram approach in the feature identification stage, as it is believed to improve significantly the performance of the pipeline for feature extraction. For example, in phrases like \textit{"The room was \textbf{as in} the \textbf{pictures"}} we deal with a potential 3-gram phrase which refers to \textit{accuracy}. A third limitation is the use of only one algorithm for detecting the sentiment of sentences of reviews. Thus, it is suggested to test a variety of sentiment detection algorithms, i.e. SO-CAL, SenticNet, Pattern, which can be trained in the corpus of Airbnb reviews for comparing their performances. Choosing the algorithm, which achieves the best results on this corpus, can probably improve the performance of the proposed approach.

The evaluation of the pipeline is another limitation of this work. The precision and recall of features are measures by using lower values of TP/FP sentences, which affects the reliability of this measurement. Thus, the evaluation must be improved either by increasing the number of features to be extracted from sentences, as discussed above, or by increasing the number of sentences in the evaluation set, in order to have more cases for evaluation. Finally, it is to be mentioned the fact that the pipeline ignores all the reviews written in languages other than English. In the dataset of Amsterdam, around 17\% of the whole reviews are ignored, meaning that at each listing, an average of 5.1 reviews are ignored. Even though the language issue is part of the limitations of every tool which deals NLP \cite{ravi2015survey}, it is suggested that this pipeline can be trained for different languages, including Dutch, French, Spanish and German, which correspond to the countries with the biggest Airbnb impact in Europe. 

% -----------------------------------------------------------

\section{Practical implications}
This paper has several practical implications for both businesses and their customers. For the last ones, having the service owners better understood the customer needs, they benefit better services. Furthermore, users will get encouraged to write more reviews as their opinions would impact the services and audience, the opposite of the case when a review ends up in the last page of reviews of a listing and it is read by less than 3\% of other users \cite{pavlou2006institutional}. In addition, if the ratings generated from text will complement the star rating system as suggested, the results would be more reliable and users' work during the decision making process would be reduced. Finally, with the right implementation of the pipeline in search engines the customers will be able to directly sort the results based on their required features. 

From the business perspective, the increase of user generated content has forced service providers to deal with the high costs of analyzing the customers data. Thus, the reduction of costs coming from outsourcing of data analysis or from salaries of employees, who manually read and analyze large amounts of text data from Web documents, blogs, reviews, personal feedback and social media sites, is a particular challenge for businesses. Having this analysis automated and detailed into discrete opinion scores significantly not only minimizes the costs, but also saves time and reduces the workload. Secondly, having the insights of text reviews in the form of quantitative data allows businesses to customize their analysis. In addition, it does not require high level skills for the employee to perform the analysis, because the output of the pipeline is just a traditional format of quantitative data, suitable for data analysis with Excel, SPSS, STATA, MATLAB and so further. Thirdly, it gives to businesses the advantage of measuring the impact of their product or services in the crowds and keeping track of the changes. For example, if a company continuously improves the quality of some certain features of their services/products, they can see how the sentiment scores of customer reviews, particularly for the feature under inspection, change over time. Lastly, this analysis provides to businesses a clear panorama of the aspects that their customers appreciate more, that their customers are unsatisfied with, that their competitors are doing better or the aspects, that their own services are superior in the market. This detailed overview is very important for businesses, as it increases the knowledge of companies on market research. 